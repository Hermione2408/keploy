// +build ignore

#include <linux/types.h>
#include <bpf/bpf_helpers.h>
#include <bpf/bpf_core_read.h>
#include "vmlinux.h"
#include "bpf_endian.h"
#include "bpf_tracing.h"

// For Kprobing.
#define socklen_t size_t

// Data buffer message size. BPF can submit at most this amount of data to a perf buffer.
// Kernel size limit is 32KiB. See https://github.com/iovisor/bcc/issues/2519 for more details.
// #define MAX_MSG_SIZE 30720 // 30KiB
#define MAX_MSG_SIZE 16384 // 16KB
// #define MAX_MSG_SIZE 2048
// #define MAX_MSG_SIZE 8192

// for protocol analyze need to read
// #define MAX_PROTOCOL_SOCKET_READ_LENGTH 31
// for transmit to the user space
// #define MAX_TRANSMIT_SOCKET_READ_LENGTH 2047

// This defines how many chunks a perf_submit can support.
// This applies to messages that are over MAX_MSG_SIZE,
// and effectively makes the maximum message size to be CHUNK_LIMIT*MAX_MSG_SIZE.
// Maximum chunk_limit recored is 81 beyond that it says ->
// load program: argument list too long: 764: (1d) if r1 == r2 goto pc-503     ; frame1: R1_w=258048 R2_w=scalar(umax=4294967295,var_off=(0x0; 0xffffffff)): ; int by (truncated, 854 line(s) omitted)
#define CHUNK_LIMIT 80

// u32 A_PID = 373061;

u16 NEW_PORT = 5000; // Choose the desired port number
u32 NEW_IP   = 0;    // 192.168.1.23 in hexadecimal forma

// struct bpf_spin_lock {
// 	__u32 val;
// };
struct port_state {
	u32 port;
	u32 occupied;
	u32 dest_ip;
	u32 dest_port;
	struct bpf_spin_lock lock;
};

// struct dest_info {
// 	u32 dest_ip;
// 	u32 dest_port;
// };

// struct bpf_map_def SEC("maps") port_mapping = {
// 	.type        = BPF_MAP_TYPE_HASH,
// 	.key_size    = sizeof(u32),
// 	.value_size  = sizeof(struct dest_info),
// 	.max_entries = 1,
// };

// use this format for decalring map with bpf_spin_lock so, that btf is generated by using "-g" flag in the compilation cmd
struct {
	__uint(type, BPF_MAP_TYPE_ARRAY);
	__type(key, u32);
	__type(value, struct port_state);
	__uint(max_entries, 50);
} proxy_ports SEC(".maps");

struct
{
    __uint(type, BPF_MAP_TYPE_HASH);
    __type(key, u32);
    __type(value, u32);
    __uint(max_entries, 1);
} user_pid SEC(".maps");

u32 convert_network_to_host_order(u32 value) {
    u16 high_half = value >> 16;
    u16 low_half = value & 0xFFFF;

    u16 converted_high = bpf_ntohs(high_half);
    u16 converted_low = bpf_ntohs(low_half);

    return ((u32)converted_high << 16) | converted_low;
}
SEC("cgroup/connect4")
int k_connect4(struct bpf_sock_addr *ctx) {
	u64 id  = bpf_get_current_pid_tgid();
	u32 pid = id >> 32; 
    u32 indx = 0;
    u32 *A_PID = bpf_map_lookup_elem(&user_pid, &indx);
    if (A_PID == NULL) {
        return 1;
    }
	bpf_printk("connect4 expected pid: %lu, and actual pid: %lu", A_PID, pid);
	if (pid != *A_PID) {
		return 1;
	}
	bpf_printk("connect4 called [PID:%lu], Protocol: %lu\n", pid, ctx->protocol);

	volatile u32 protocol = ctx->protocol;

	if (protocol != 6) {
		return 1;
	}

	// destination ip.
	u32 dst_ip = ctx->user_ip4;
	// u16 dst_ip_u = (u16)ctx->user_ip4;
	// u32 dst_ip = (u32)bpf_ntohs(ctx->user_ip4);
    // u32 dst_ip = convert_network_to_host_order(ctx->user_ip4);
	// destination port
	u16 dst_port_u = (u16)ctx->user_port;
	u16 dst_port   = bpf_ntohs(dst_port_u);

	// check for the port_state and occupy it. the size of proxy_ports array is 50
	for (u32 i = 0; i < 50; i++) {
		const u32 index            = i;
		struct port_state *value = bpf_map_lookup_elem(&proxy_ports, &index);
		if (value && value->occupied==0) {
			bpf_printk("occupied? : %u", value->occupied);
			// if (value->occupied == 0) {
			bpf_spin_lock(&value->lock);
			value->occupied  = 1;
			NEW_PORT         = (__u32)bpf_ntohs(value->port);
			value->dest_port = dst_port;
			value->dest_ip   = dst_ip;
			bpf_spin_unlock(&value->lock);
            bpf_printk("This is the value of the destination port:%u, and this is the destination ip:%u",value->dest_port, value->dest_ip);
			break;
			// }
		}

		// if (value && value->occupied == 0) {
		// occupy the proxy running at the vaccant port and store the destination ip and port
		// bpf_spin_lock(&value->lock);
		// value->occupied = 1;
		// NEW_PORT        = (__u32)bpf_ntohs(value->port);
		// value->dest_port = dst_port;
		// bpf_spin_unlock(&value->lock);

		// 	break;
		// }
	}

	// u32 client_ip = 1;

	// struct dest_info dest = {
	// 	.dest_ip   = dst_ip,
	// 	.dest_port = dst_port,
	// };

	// struct dest_info *pdest = bpf_map_lookup_elem(&port_mapping, &client_ip);
	// bpf_printk("key address in port_access map:%p\n", &client_ip);
	// if (pdest) {
	// 	// Entry exists, update it
	// 	bpf_printk("Entry exists in the port_access map, hence getting the [dest_ip:%lu] and [dest_port:%lu]\n", pdest->dest_ip, pdest->dest_port);
	// 	*pdest = dest;
	// } else {
	// 	// Entry does not exist, insert it
	// 	bpf_printk("Entry doesn't exist in the port_access map, hence setting the [dest_ip:%lu]and [dest_port:%lu]\n", dest.dest_ip, dest.dest_port);
	// 	bpf_map_update_elem(&port_mapping, &client_ip, &dest, BPF_ANY);
	// }

	// bpf_map_pop_elem(&proxy_ports, value);
	// 	u32 *value2 = bpf_map_lookup_elem(&proxy_ports, &index);
	// 	bpf_printk("vaccant proxy at port:%u\n", *value2);
	// }
	// redirecting to proxy.
	ctx->user_ip4  = NEW_IP;
	ctx->user_port = NEW_PORT;
	bpf_printk("destination IP: %u | destination Port: %u", ctx->user_ip4, ctx->user_port);
	return 1;
}

SEC("cgroup/connect6")
int k_connect6(struct bpf_sock_addr *ctx) {

    u64 id  = bpf_get_current_pid_tgid();
	u32 pid = id >> 32, indx = 0;
    u32 *A_PID = bpf_map_lookup_elem(&user_pid, &indx);
    if (A_PID == NULL) {
        return 1;
    }
	bpf_printk("connect6 expected pid: %lu, and actual pid: %lu", A_PID, pid);
	if (pid != *A_PID) {
		return 1;
	}
	bpf_printk("connect6 called [PID:%lu], Protocol: %lu\n", pid, ctx->protocol);
    return 1;
}

SEC("cgroup/getpeername4")
int k_getpeername4(struct bpf_sock_addr *ctx) {
	u64 pid = bpf_get_current_pid_tgid() >> 32;
	bpf_printk("getpeername4 called [PID:%llu]\n", pid);
	return 1;

    // u64 id  = bpf_get_current_pid_tgid();
	// u32 pid = id >> 32;
	// bpf_printk("getpeername4 expected pid: %lu, and calling process pid: %lu", A_PID, pid);
	// if (pid != *A_PID) {
	// 	return 1;
	// }
	// bpf_printk("getpeername4 called [PID:%lu]\n", pid);

	// volatile u32 protocol = ctx->protocol;

	// if (protocol != 6) {
	// 	return 1;
	// }

	// // destination ip.
	// u32 dst_ip = ctx->user_ip4;
	// // u16 dst_ip_u = (u16)ctx->user_ip4;
	// // u32 dst_ip = (u32)bpf_ntohs(ctx->user_ip4);
	// // destination port
	// u16 dst_port_u = (u16)ctx->user_port;
	// u16 dst_port   = bpf_ntohs(dst_port_u);

	// // check for the port_state and occupy it. the size of proxy_ports array is 50
	// for (u32 i = 0; i < 50; i++) {
	// 	const u32 index            = i;
	// 	struct port_state *value = bpf_map_lookup_elem(&proxy_ports, &index);
	// 	if (value && value->occupied==0) {
	// 		bpf_printk("occupied? : %u", value->occupied);
	// 		// if (value->occupied == 0) {
	// 		bpf_spin_lock(&value->lock);
	// 		value->occupied  = 1;
	// 		NEW_PORT         = (__u32)bpf_ntohs(value->port);
	// 		value->dest_port = dst_port;
	// 		value->dest_ip   = dst_ip;
	// 		bpf_spin_unlock(&value->lock);
	// 		break;
	// 		// }
	// 	}
	// }

	// ctx->user_ip4  = NEW_IP;
	// ctx->user_port = NEW_PORT;
	// bpf_printk("destination IP: %u | destination Port: %u", ctx->user_ip4, ctx->user_port);
	// return 1;
}

// KProbing

// Capturing incoming http requests and responses using kprobes.

enum traffic_direction_t
{
    kEgress,
    kIngress,
};

// Structs

// A struct representing a unique ID that is composed of the pid, the file
// descriptor and the creation time of the struct.
struct conn_id_t
{
    // Process ID
    u32 pid;
    // The file descriptor to the opened network connection.
    s32 fd;
    // Timestamp at the initialization of the struct.
    u64 tsid;
};

// This struct contains information collected when a connection is established,
// via an accept4() syscall.
struct conn_info_t
{
    // Connection identifier.
    struct conn_id_t conn_id;

    // The number of bytes written/read on this connection.
    s64 wr_bytes;
    s64 rd_bytes;

    // A flag indicating we identified the connection as HTTP.
    bool is_http;
};

// An helper struct that hold the addr argument of the syscall.
struct accept_args_t
{
    struct sockaddr_in addr;
};

// An helper struct to cache input argument of read/write syscalls between the
// entry hook and the exit hook.
struct data_args_t
{
    s32 fd;
    char *buf;
};

// An helper struct that hold the input arguments of the close syscall.
struct close_args_t
{
    s32 fd;
};

// A struct describing the event that we send to the user mode upon a new connection.
struct socket_open_event_t
{
    // The time of the event.
    u64 timestamp_ns;
    // A unique ID for the connection.
    struct conn_id_t conn_id;
    // The address of the client.
    struct sockaddr_in addr;
};

// Struct describing the close event being sent to the user mode.
struct socket_close_event_t
{
    // Timestamp of the close syscall
    u64 timestamp_ns;
    // The unique ID of the connection
    struct conn_id_t conn_id;
    // Total number of bytes written on that connection
    s64 wr_bytes;
    // Total number of bytes read on that connection
    s64 rd_bytes;
};

struct socket_data_event_t
{

    // The timestamp when syscall completed (return probe was triggered).
    u64 timestamp_ns;

    // Connection identifier (PID, FD, etc.).
    struct conn_id_t conn_id;

    // The type of the actual data that the msg field encodes, which is used by the caller
    // to determine how to interpret the data.
    enum traffic_direction_t direction;

    // The size of the original message. We use this to truncate msg field to minimize the amount
    // of data being transferred.
    u32 msg_size;

    // A 0-based position number for this event on the connection, in terms of byte position.
    // The position is for the first byte of this message.
    u64 pos;
    // Actual buffer
    char msg[MAX_MSG_SIZE];
};

struct
{
    __uint(type, BPF_MAP_TYPE_HASH);
    __type(key, u64);
    __type(value, struct conn_info_t);
    __uint(max_entries, 131072);
} conn_info_map SEC(".maps");

struct
{
    __uint(type, BPF_MAP_TYPE_HASH);
    __type(key, u64);
    __type(value, struct accept_args_t);
    __uint(max_entries, 1024);
} active_accept_args_map SEC(".maps");

struct
{
    __uint(type, BPF_MAP_TYPE_HASH);
    __type(key, u64);
    __type(value, struct data_args_t);
    __uint(max_entries, 1024);
} active_write_args_map SEC(".maps");

struct
{
    __uint(type, BPF_MAP_TYPE_HASH);
    __type(key, u64);
    __type(value, struct data_args_t);
    __uint(max_entries, 1024);
} active_read_args_map SEC(".maps");

struct
{
    __uint(type, BPF_MAP_TYPE_HASH);
    __type(key, u64);
    __type(value, struct close_args_t);
    __uint(max_entries, 1024);
} active_close_args_map SEC(".maps");

struct
{
    __uint(type, BPF_MAP_TYPE_PERF_EVENT_ARRAY);
} socket_open_events SEC(".maps");

// struct
// {
//     __uint(type, BPF_MAP_TYPE_PERF_EVENT_ARRAY);
// } socket_data_events SEC(".maps");

struct
{
    __uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);
    __type(key, u32);
    __type(value, struct socket_data_event_t);
    __uint(max_entries, 1);
} socket_data_event_buffer_heap SEC(".maps");

struct
{
    __uint(type, BPF_MAP_TYPE_RINGBUF);
    __uint(max_entries, 1 << 24); //  16 MB
} socket_data_events SEC(".maps");

struct
{
    __uint(type, BPF_MAP_TYPE_PERF_EVENT_ARRAY);
} socket_close_events SEC(".maps");

// Helper functions

// An helper function that checks if the syscall finished successfully and if it did
// saves the new connection in a dedicated map of connections
static __inline void process_syscall_accept(struct pt_regs *ctx, u64 id, const struct accept_args_t *args)
{
    // Extracting the return code, and checking if it represent a failure,
    // if it does, we abort the as we have nothing to do.
    s32 ret_fd = PT_REGS_RC(ctx);
    if (ret_fd <= 0)
    {
        return;
    }

    struct conn_info_t conn_info = {};
    u32 pid = id >> 32;
    conn_info.conn_id.pid = pid;
    conn_info.conn_id.fd = ret_fd;
    conn_info.conn_id.tsid = bpf_ktime_get_ns();

    u64 pid_fd = ((u64)pid << 32) | (u32)ret_fd;
    // Saving the connection info in a global map, so in the other syscalls
    // (read, write and close) we will be able to know that we have seen
    // the connection
    bpf_map_update_elem(&conn_info_map, &pid_fd, &conn_info, BPF_ANY);

    // Sending an open event to the user mode, to let the user mode know that we
    // have identified a new connection.
    struct socket_open_event_t open_event = {};
    open_event.timestamp_ns = bpf_ktime_get_ns();
    open_event.conn_id = conn_info.conn_id;
    bpf_probe_read(&open_event.addr, sizeof(open_event.addr), &(args->addr));

    bpf_perf_event_output(ctx, &socket_open_events, BPF_F_CURRENT_CPU, &open_event, sizeof(struct socket_open_event_t));
}

static __inline u64 gen_tgid_fd(u32 tgid, u32 sockfd)
{
    return ((u64)tgid << 32) | sockfd;
}

static inline __attribute__((__always_inline__)) void process_syscall_close(struct pt_regs *ctx, u64 id, const struct close_args_t *close_args)
{
    s32 ret_val = PT_REGS_RC(ctx);
    if (ret_val < 0)
    {
        return;
    }

    u32 tgid = id >> 32;
    u64 tgid_fd = gen_tgid_fd(tgid, close_args->fd);
    // bpf_printk("Before lookup in the close map");
    struct conn_info_t *conn_info = bpf_map_lookup_elem(&conn_info_map, &tgid_fd);
    // bpf_printk("After lookup in the close map");

    if (conn_info == NULL)
    {
        // The FD being closed does not represent an IPv4 socket FD.
        // bpf_printk("connection info is NULLLLL");
        return;
    }
    else
    {
        // bpf_printk("connection info is NOT NULLLLL");
    }

    // Send to the user mode an event indicating the connection was closed.
    struct socket_close_event_t close_event = {};
    close_event.timestamp_ns = bpf_ktime_get_ns();
    close_event.conn_id = conn_info->conn_id;
    close_event.rd_bytes = conn_info->rd_bytes;
    close_event.wr_bytes = conn_info->wr_bytes;

    bpf_printk("Connection closed... rd_bytes[%llu] || wr_bytes[%llu]", close_event.rd_bytes, close_event.wr_bytes);
    bpf_perf_event_output(ctx, &socket_close_events, BPF_F_CURRENT_CPU, &close_event, sizeof(struct socket_close_event_t));

    // Remove the connection from the mapping.
    int ret = bpf_map_delete_elem(&conn_info_map, &tgid_fd);
    if (ret)
    {
        // Handle the error...
        // bpf_printk("[process_syscall_close]:error deleting the entry from the conn_info_map:%d\n", ret);
    }
}

static inline __attribute__((__always_inline__)) bool is_http_connection(struct conn_info_t *conn_info, const char *buf, size_t count)
{
    // If the connection was already identified as HTTP connection, no need to re-check it.
    // bpf_printk("[%llu]Bytes count before checking http:%d", bpf_ktime_get_ns(), count);
    if (conn_info->is_http)
    {
        return true;
    }

    // The minimum length of http request or response.
    if (count < 16)
    {
        return false;
    }

    // bpf_printk("[%llu]Bytes count before reading in is_http_connection:%d", bpf_ktime_get_ns(), count);
    // bpf_printk("Buffer in is_http_connection():\n%s", buf);

    // Did the below thing, because directly accessing buf indices was giving permission denied error.
    char check[12];
    bpf_probe_read(&check, sizeof(check), buf);
    // bpf_printk("Buffer in check http:%s", check);
    // bpf_printk("[%llu]Bytes count after reading in is_http_connection:%d", bpf_ktime_get_ns(), count);
    bool res = false;
    if (check[0] == 'H' && check[1] == 'T' && check[2] == 'T' && check[3] == 'P')
    {
        res = true;
    }
    if (check[0] == 'G' && check[1] == 'E' && check[2] == 'T')
    {
        res = true;
    }
    if (check[0] == 'P' && check[1] == 'O' && check[2] == 'S' && check[3] == 'T')
    {
        res = true;
    }
    if (check[0] == 'P' && check[1] == 'U' && check[2] == 'T')
    {
        res = true;
    }
    if (check[0] == 'D' && check[1] == 'E' && check[2] == 'L' && check[3] == 'E' && check[4] == 'T' && check[5] == 'E')
    {
        res = true;
    }
    if (check[0] == 'H' && check[1] == 'E' && check[2] == 'A' && check[3] == 'D')
    {
        res = true;
    }
    if (check[0] == 'P' && check[1] == 'A' && check[2] == 'T' && check[3] == 'C' && check[4] == 'H')
    {
        res = true;
    }

    // Add other HTTP request methods here if needed.

    if (res)
    {
        conn_info->is_http = true;
    }

    return res;
}

// ring buffer
static __inline void perf_submit_buf(struct pt_regs *ctx, const enum traffic_direction_t direction, char *buf, int buf_size, int offset, struct conn_info_t *conn_info, struct socket_data_event_t *event)

{

    switch (direction)
    {
    case kEgress:
        event->pos = conn_info->wr_bytes + offset;
        break;
    case kIngress:
        event->pos = conn_info->rd_bytes + offset;
        break;
    }

    // // 30720 bytes
    // // 0x77ff is hexadecimal number of 30719
    // bpf_printk("Before Magic perf_submit_buf...[buf_size:%llu]", buf_size);
    // asm volatile("%[buf_size] &= 0x77ff;\n" ::[buf_size] "+r"(buf_size)
    //              :);

    // // bpf_printk("After Magic perf_submit_buf...[buf_size:%llu]", buf_size);
    // bpf_probe_read(&event->msg, buf_size & 0x77ff, buf);

    // 16384 bytes
    // 0x3fff is hexadecimal number of 16383
    asm volatile("%[buf_size] &= 0x3fff;\n" ::[buf_size] "+r"(buf_size)
                 :);
    bpf_probe_read(&event->msg, buf_size & 0x3fff, buf);

    // bpf_printk("about to submit the event....");
    if (buf_size > 0)
    {
        event->msg_size = buf_size;
        bpf_printk("Final buffer size of Event:%lu", event->msg_size);
        // bpf_printk("[%llu]Size of data event %llu", bpf_ktime_get_ns(), sizeof(*event) - buf_size);
        // bpf_printk("[%llu]Buffer size:%llu", bpf_ktime_get_ns(), buf_size);
        // bpf_perf_event_output(ctx, &socket_data_events, BPF_F_CURRENT_CPU, event, sizeof(*event));
        // bpf_ringbuf_submit(event, 0);
        // bpf_printk("submitting the socket_data_event...");
        bpf_ringbuf_output(&socket_data_events, event, sizeof(*event), 0);
    }
}

static __inline void perf_submit_wrapper(struct pt_regs *ctx, const enum traffic_direction_t direction, char *buf, int buf_size, struct conn_info_t *conn_info, struct socket_data_event_t *event)
{

    // perf_submit_buf(ctx, direction, buf, buf_size, buf_size, conn_info, event);
    // perf_submit_buf(ctx, direction, buf + 10, buf_size + 10, buf_size + 5, conn_info, event);

    int bytes_sent = 0;
    unsigned int i;
    // bpf_printk("[%llu]:Buffer size in perf_submit_wrapper:%d", bpf_ktime_get_ns(), buf_size);
// #pragma clang loop unroll(full)
#pragma unroll
    for (i = 0; i < CHUNK_LIMIT; ++i)
    {
        int bytes_remaining = buf_size - bytes_sent;
        int current_size = (bytes_remaining > MAX_MSG_SIZE && (i != CHUNK_LIMIT - 1)) ? MAX_MSG_SIZE : bytes_remaining;
        perf_submit_buf(ctx, direction, buf + bytes_sent, current_size, bytes_sent, conn_info, event);
        bytes_sent += current_size;
        if (buf_size == bytes_sent)
        {
            return;
        }
    }
}

static inline __attribute__((__always_inline__)) void process_data(struct pt_regs *ctx, u64 id, enum traffic_direction_t direction, const struct data_args_t *args, int bytes_count)
{
    // Always check access to pointer before accessing them.
    if (args->buf == NULL)
    {
        return;
    }

    // For read and write syscall, the return code is the number of bytes written or read, so zero means nothing
    // was written or read, and negative means that the syscall failed. Anyhow, we have nothing to do with that syscall.
    // bpf_printk("[%llu]:Before check Buffer size in process_data:%d", bpf_ktime_get_ns(), bytes_count);

    if (bytes_count <= 0)
    {
        // bpf_printk("GOT NEGATIVE BYTE SIZE....");
        return;
    }
    // bpf_printk("[%llu]:After check Buffer size in process_data:%d", bpf_ktime_get_ns(), bytes_count);

    u32 pid = id >> 32;
    u64 pid_fd = ((u64)pid << 32) | (u32)args->fd;

    struct conn_info_t *conn_info = bpf_map_lookup_elem(&conn_info_map, &pid_fd);
    if (conn_info == NULL)
    {
        // The FD being read/written does not represent an IPv4 socket FD.
        return;
    }
    if (direction == kEgress)
    {
        // bpf_printk("Checking for ishttp response()");
    }
    else
    {
        // bpf_printk("Checking for ishttp request()");
    }
    // Check if the connection is already HTTP, or check if that's a new connection, check protocol and return true if that's HTTP.
    if (is_http_connection(conn_info, args->buf, bytes_count))
    {
        // bpf_printk("Yes it is http...");
        // allocate new event.
        u32 kZero = 0;
        // only lookup no update because each entry of the map is pre-allocated here.
        struct socket_data_event_t *event = bpf_map_lookup_elem(&socket_data_event_buffer_heap, &kZero);
        if (!event)
        {
            // bpf_printk("[%llu]: unable to allocate memory for data event...", bpf_ktime_get_ns());
            return;
        }
        else
        {
            // bpf_printk("[%llu]: memory allocated successfully...", bpf_ktime_get_ns());
        }

        // struct socket_data_event_t *event = bpf_ringbuf_reserve(&socket_data_events, sizeof(struct socket_data_event_t), 0);
        // if (!event)
        // {
        //     bpf_printk("[%llu]: unable to allocate [%llu] memory for data event...", sizeof(struct socket_data_event_t), bpf_ktime_get_ns());
        //     return;
        // }

        // Fill the metadata of the data event.
        event->timestamp_ns = bpf_ktime_get_ns();
        event->direction = direction;
        event->conn_id = conn_info->conn_id;

        // bpf_ringbuf_submit(event, 0);
        perf_submit_wrapper(ctx, direction, args->buf, bytes_count, conn_info, event);
    }

    // Update the conn_info total written/read bytes.
    switch (direction)
    {
    case kEgress:
        conn_info->wr_bytes += bytes_count;
        break;
    case kIngress:
        conn_info->rd_bytes += bytes_count;
        break;
    }
}

// Hooks
// accept sys call
SEC("kprobe/sys_accept")
int syscall__probe_entry_accept(struct pt_regs *ctx)
{

    u64 id = bpf_get_current_pid_tgid();
    u32 pid = id >> 32, indx = 0;
    u32 *A_PID = bpf_map_lookup_elem(&user_pid, &indx);
    if (A_PID == NULL) {
        return 1;
    }
    if (pid != *A_PID)
        return 0;

    struct pt_regs *__ctx = (struct pt_regs *)PT_REGS_PARM1_CORE(ctx);
    if (!__ctx)
    {
        // bpf_printk("[sys_accept_entry]:failed to load original ctx");
        return 0;
    }

    // bpf_printk("[sys_accept_entry]:called for [PID:%lu]\n", pid);

    // Create a new accept_args_t struct
    struct accept_args_t accept_args = {};

    bpf_probe_read(&accept_args.addr, sizeof(accept_args.addr), &(PT_REGS_PARM2(__ctx)));
    bpf_map_update_elem(&active_accept_args_map, &id, &accept_args, BPF_ANY);

    return 0;
}

SEC("kretprobe/sys_accept")
int syscall__probe_ret_accept(struct pt_regs *ctx)
{
    u64 id = bpf_get_current_pid_tgid();
    u32 pid = id >> 32, indx = 0;
    u32 *A_PID = bpf_map_lookup_elem(&user_pid, &indx);
    if (A_PID == NULL) {
        return 1;
    }
    if (pid != *A_PID)
        return 0;
    // bpf_printk("[sys_accept_exit]:called for [PID:%lu]\n", pid);

    // // Pulling the addr from the map.
    const struct accept_args_t *accept_args = bpf_map_lookup_elem(&active_accept_args_map, &id);
    if (accept_args)
    {
        process_syscall_accept(ctx, id, accept_args);

        int ret = bpf_map_delete_elem(&active_accept_args_map, &id);
        if (ret)
        {
            // Handle the error...
            // bpf_printk("[sys_accept_exit]:error deleting the entry from the active_accept_args_map:%d\n", ret);
        }
    }
    return 0;
}

// accept4 sys call
SEC("kprobe/sys_accept4")
int syscall__probe_entry_accept4(struct pt_regs *ctx)
{

    u64 id = bpf_get_current_pid_tgid();
    u32 pid = id >> 32, indx = 0;
    u32 *A_PID = bpf_map_lookup_elem(&user_pid, &indx);
    if (A_PID == NULL) {
        return 1;
    }
    if (pid != *A_PID)
        return 0;

    struct pt_regs *__ctx = (struct pt_regs *)PT_REGS_PARM1_CORE(ctx);
    if (!__ctx)
    {
        // bpf_printk("[sys_accept4_entry]:failed to load original ctx");
        return 0;
    }

    // bpf_printk("[sys_accept4_entry]:called for [PID:%lu]\n", pid);

    // Create a new accept_args_t struct
    struct accept_args_t accept_args = {};
    bpf_probe_read(&accept_args.addr, sizeof(accept_args.addr), &(PT_REGS_PARM2(__ctx)));
    bpf_map_update_elem(&active_accept_args_map, &id, &accept_args, BPF_ANY);

    return 0;
}

SEC("kretprobe/sys_accept4")
int syscall__probe_ret_accept4(struct pt_regs *ctx)
{
    u64 id = bpf_get_current_pid_tgid();
    u32 pid = id >> 32, indx = 0;
    u32 *A_PID = bpf_map_lookup_elem(&user_pid, &indx);
    if (A_PID == NULL) {
        return 1;
    }
    if (pid != *A_PID)
        return 0;
    // bpf_printk("[sys_accept4_exit]:called for [PID:%lu]\n", pid);

    // // Pulling the addr from the map.
    const struct accept_args_t *accept_args = bpf_map_lookup_elem(&active_accept_args_map, &id);
    if (accept_args)
    {
        process_syscall_accept(ctx, id, accept_args);

        int ret = bpf_map_delete_elem(&active_accept_args_map, &id);
        if (ret)
        {
            // Handle the error...
            // bpf_printk("[sys_accept4_exit]:error deleting the entry from the active_accept_args_map:%d\n", ret);
        }
    }
    return 0;
}

// read sys call
SEC("kprobe/sys_read")
int syscall__probe_entry_read(struct pt_regs *ctx)
{
    u64 id = bpf_get_current_pid_tgid();
    u32 pid = id >> 32, indx = 0;
    u32 *A_PID = bpf_map_lookup_elem(&user_pid, &indx);
    if (A_PID == NULL) {
        return 1;
    }
    if (pid != *A_PID)
        return 0;

    struct pt_regs *__ctx = (struct pt_regs *)PT_REGS_PARM1_CORE(ctx);
    if (!__ctx)
    {
        // bpf_printk("[sys_read_entry]:failed to load original ctx");
        return 0;
    }

    // bpf_printk("[sys_read_entry]:called for [PID:%lu]\n", pid);

    // Stash arguments
    struct data_args_t read_args = {};

    read_args.fd = (int)PT_REGS_PARM1_CORE(__ctx);
    char *read_buf = (char *)PT_REGS_PARM2_CORE(__ctx);

    if (!read_buf)
    {
        // bpf_printk("[sys_read_entry]:read buf is null");
        return 0;
    }

    read_args.buf = read_buf;
    bpf_map_update_elem(&active_read_args_map, &id, &read_args, BPF_ANY);
    return 0;
}

SEC("kretprobe/sys_read")
int syscall__probe_ret_read(struct pt_regs *ctx)
{
    u64 id = bpf_get_current_pid_tgid();
    u32 pid = id >> 32, indx = 0;
    u32 *A_PID = bpf_map_lookup_elem(&user_pid, &indx);
    if (A_PID == NULL) {
        return 1;
    }
    if (pid != *A_PID)
        return 0;

    // bpf_printk("[sys_read_exit]:called for [PID:%lu]\n", pid);

    // The return code the syscall is the number of bytes read as well.
    size_t bytes_count = PT_REGS_RC(ctx); // Also stands for return code.
    // if ((int)bytes_count > 0)
        // bpf_printk("[sys_read_exit]: return code:%d", bytes_count);

    struct data_args_t *read_args = bpf_map_lookup_elem(&active_read_args_map, &id);
    if (read_args)
    {
        // // kIngress is an enum value that let's the process_data function
        // // to know whether the input buffer is incoming or outgoing.

        // bpf_printk("[sys_read_exit]: read buffer:%s", read_args->buf);

        process_data(ctx, id, kIngress, read_args, bytes_count);

        int ret = bpf_map_delete_elem(&active_read_args_map, &id);
        if (ret)
        {
            // Handle the error...
            // bpf_printk("[sys_read_exit]:error deleting the entry from the active_read_args_map:%d\n", ret);
        }
    }
    return 0;
}

// write sys call
SEC("kprobe/sys_write")
int syscall__probe_entry_write(struct pt_regs *ctx)
{
    u64 id = bpf_get_current_pid_tgid();
    u32 pid = id >> 32, indx = 0;
    u32 *A_PID = bpf_map_lookup_elem(&user_pid, &indx);
    if (A_PID == NULL) {
        return 1;
    }
    if (pid != *A_PID)
        return 0;

    struct pt_regs *__ctx = (struct pt_regs *)PT_REGS_PARM1_CORE(ctx);
    if (!__ctx)
    {
        // bpf_printk("[sys_write_entry]:failed to load original ctx");
        return 0;
    }

    // bpf_printk("[sys_write_entry]:called for [PID:%lu]\n", pid);

    // Stash arguments
    struct data_args_t write_args = {};

    write_args.fd = (int)PT_REGS_PARM1_CORE(__ctx);
    char *write_buf = (char *)PT_REGS_PARM2_CORE(__ctx);

    if (!write_buf)
    {
        // bpf_printk("[sys_write_entry]:write buf is null");
        return 0;
    }

    write_args.buf = write_buf;
    bpf_map_update_elem(&active_write_args_map, &id, &write_args, BPF_ANY);
    return 0;
}

SEC("kretprobe/sys_write")
int syscall__probe_ret_write(struct pt_regs *ctx)
{
    u64 id = bpf_get_current_pid_tgid();
    u32 pid = id >> 32, indx = 0;
    u32 *A_PID = bpf_map_lookup_elem(&user_pid, &indx);
    if (A_PID == NULL) {
        return 1;
    }
    if (pid != *A_PID)
        return 0;

    // bpf_printk("[sys_write_exit]:called for [PID:%lu]\n", pid);

    // The return code the syscall is the number of bytes read as well.
    size_t bytes_count = PT_REGS_RC(ctx); // Also stands for return code.
    // if ((int)bytes_count > 0)
        // bpf_printk("[sys_write_exit]: return code:%d", bytes_count);

    struct data_args_t *write_args = bpf_map_lookup_elem(&active_write_args_map, &id);
    if (write_args)
    {
        // // KEgress is an enum value that let's the process_data function
        // // to know whether the output buffer is incoming or outgoing.

        // bpf_printk("[sys_write_exit]: write buffer:%s", write_args->buf);

        process_data(ctx, id, kEgress, write_args, bytes_count);

        int ret = bpf_map_delete_elem(&active_write_args_map, &id);
        if (ret)
        {
            // Handle the error...
            // bpf_printk("[sys_write_exit]:error deleting the entry from the active_write_args_map:%d\n", ret);
        }
    }
    return 0;
}

// close sys call
//  // original signature: int close(int fd)
SEC("kprobe/sys_close")
int syscall__probe_entry_close(struct pt_regs *ctx, int fd)
{
    u64 id = bpf_get_current_pid_tgid();
    u32 pid = id >> 32, indx = 0;
    u32 *A_PID = bpf_map_lookup_elem(&user_pid, &indx);
    if (A_PID == NULL) {
        return 1;
    }
    if (pid != *A_PID)
        return 0;

    struct pt_regs *__ctx = (struct pt_regs *)PT_REGS_PARM1_CORE(ctx);
    if (!__ctx)
    {
        // bpf_printk("[sys_close_entry]:failed to load original ctx");
        return 0;
    }

    // bpf_printk("[sys_close_entry]:called for [PID:%lu]\n", pid);

    struct close_args_t close_args = {};
    close_args.fd = (PT_REGS_PARM1_CORE(__ctx));

    bpf_map_update_elem(&active_close_args_map, &id, &close_args, BPF_ANY);
    return 0;
}

SEC("kretprobe/sys_close")
int syscall__probe_ret_close(struct pt_regs *ctx)
{
    u64 id = bpf_get_current_pid_tgid();
    u32 pid = id >> 32, indx = 0;
    u32 *A_PID = bpf_map_lookup_elem(&user_pid, &indx);
    if (A_PID == NULL) {
        return 1;
    }
    if (pid != *A_PID)
        return 0;

    // bpf_printk("[sys_close_exit]:called for [PID:%lu]\n", pid);

    struct close_args_t *close_args = bpf_map_lookup_elem(&active_close_args_map, &id);
    if (close_args)
    {
        process_syscall_close(ctx, id, close_args);
        int ret = bpf_map_delete_elem(&active_close_args_map, &id);
        if (ret)
        {
            // Handle the error...
            // bpf_printk("[sys_write_exit]:error deleting the entry from the active_close_args_map:%d\n", ret);
        }
    }
    return 0;
}

SEC("uprobe/SSL_write")
int uprobe_entry_SSL_write(struct pt_regs *ctx)
{
  u64 processThreadID = bpf_get_current_pid_tgid();
  char *user_space_buf = (char *)PT_REGS_PARM2(ctx);
    if (!user_space_buf)
    {
        bpf_printk("[uprobe_entry_SSL_write]:user_space_buf is null");
        return 0;
    }
    else
    {
        bpf_printk("[uprobe_entry_SSL_write]:user_space_buf:%s and processThreadID:%d", user_space_buf, processThreadID);
    }


  return 0;
}

char _license[] SEC("license") = "GPL";
